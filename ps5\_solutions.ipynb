{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5229a382",
   "metadata": {},
   "source": [
    "# Anton Melnychuk ECON 3385 - Problem Set 5\n",
    "\n",
    "February 16th, 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6af7f0",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e24ccaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_city</th>\n",
       "      <th>quarter</th>\n",
       "      <th>avg_pop</th>\n",
       "      <th>price_AA</th>\n",
       "      <th>price_DL</th>\n",
       "      <th>price_Other</th>\n",
       "      <th>price_UA</th>\n",
       "      <th>logp_AA</th>\n",
       "      <th>logp_DL</th>\n",
       "      <th>logp_Other</th>\n",
       "      <th>...</th>\n",
       "      <th>passengers_Other</th>\n",
       "      <th>passengers_UA</th>\n",
       "      <th>logq_AA</th>\n",
       "      <th>logq_DL</th>\n",
       "      <th>logq_Other</th>\n",
       "      <th>logq_UA</th>\n",
       "      <th>avg_hub_AA</th>\n",
       "      <th>avg_hub_DL</th>\n",
       "      <th>avg_hub_Other</th>\n",
       "      <th>avg_hub_UA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL to DEN</td>\n",
       "      <td>2</td>\n",
       "      <td>634.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>139.25</td>\n",
       "      <td>150.0</td>\n",
       "      <td>5.549076</td>\n",
       "      <td>3.784190</td>\n",
       "      <td>4.936271</td>\n",
       "      <td>...</td>\n",
       "      <td>7450.0</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>9.836813</td>\n",
       "      <td>8.915969</td>\n",
       "      <td>7.426549</td>\n",
       "      <td>25.5</td>\n",
       "      <td>41.0</td>\n",
       "      <td>16.625</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL to DEN</td>\n",
       "      <td>3</td>\n",
       "      <td>634.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>139.75</td>\n",
       "      <td>119.0</td>\n",
       "      <td>5.147494</td>\n",
       "      <td>3.637586</td>\n",
       "      <td>4.939855</td>\n",
       "      <td>...</td>\n",
       "      <td>7440.0</td>\n",
       "      <td>1710.0</td>\n",
       "      <td>4.382027</td>\n",
       "      <td>10.057500</td>\n",
       "      <td>8.914626</td>\n",
       "      <td>7.444249</td>\n",
       "      <td>28.5</td>\n",
       "      <td>42.0</td>\n",
       "      <td>18.000</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATL to DEN</td>\n",
       "      <td>4</td>\n",
       "      <td>634.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>78.00</td>\n",
       "      <td>93.0</td>\n",
       "      <td>4.605170</td>\n",
       "      <td>4.060443</td>\n",
       "      <td>4.356709</td>\n",
       "      <td>...</td>\n",
       "      <td>7230.0</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>5.521461</td>\n",
       "      <td>9.877144</td>\n",
       "      <td>8.885994</td>\n",
       "      <td>8.237479</td>\n",
       "      <td>28.0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>18.000</td>\n",
       "      <td>33.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATL to ORD</td>\n",
       "      <td>1</td>\n",
       "      <td>1640.5</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>52.00</td>\n",
       "      <td>96.0</td>\n",
       "      <td>4.663439</td>\n",
       "      <td>4.248495</td>\n",
       "      <td>3.951244</td>\n",
       "      <td>...</td>\n",
       "      <td>14610.0</td>\n",
       "      <td>42900.0</td>\n",
       "      <td>9.801455</td>\n",
       "      <td>11.233210</td>\n",
       "      <td>9.589461</td>\n",
       "      <td>10.666630</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>17.000</td>\n",
       "      <td>38.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATL to ORD</td>\n",
       "      <td>2</td>\n",
       "      <td>1640.5</td>\n",
       "      <td>137.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>149.0</td>\n",
       "      <td>4.919981</td>\n",
       "      <td>3.850147</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>...</td>\n",
       "      <td>13980.0</td>\n",
       "      <td>12260.0</td>\n",
       "      <td>9.382611</td>\n",
       "      <td>11.297750</td>\n",
       "      <td>9.545383</td>\n",
       "      <td>9.414097</td>\n",
       "      <td>31.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>14.000</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   route_city  quarter  avg_pop  price_AA  price_DL  price_Other  price_UA  \\\n",
       "0  ATL to DEN        2    634.0     257.0      44.0       139.25     150.0   \n",
       "1  ATL to DEN        3    634.0     172.0      38.0       139.75     119.0   \n",
       "2  ATL to DEN        4    634.0     100.0      58.0        78.00      93.0   \n",
       "3  ATL to ORD        1   1640.5     106.0      70.0        52.00      96.0   \n",
       "4  ATL to ORD        2   1640.5     137.0      47.0        30.00     149.0   \n",
       "\n",
       "    logp_AA   logp_DL  logp_Other  ...  passengers_Other  passengers_UA  \\\n",
       "0  5.549076  3.784190    4.936271  ...            7450.0         1680.0   \n",
       "1  5.147494  3.637586    4.939855  ...            7440.0         1710.0   \n",
       "2  4.605170  4.060443    4.356709  ...            7230.0         3780.0   \n",
       "3  4.663439  4.248495    3.951244  ...           14610.0        42900.0   \n",
       "4  4.919981  3.850147    3.401197  ...           13980.0        12260.0   \n",
       "\n",
       "    logq_AA    logq_DL  logq_Other    logq_UA  avg_hub_AA  avg_hub_DL  \\\n",
       "0  2.995732   9.836813    8.915969   7.426549        25.5        41.0   \n",
       "1  4.382027  10.057500    8.914626   7.444249        28.5        42.0   \n",
       "2  5.521461   9.877144    8.885994   8.237479        28.0        37.5   \n",
       "3  9.801455  11.233210    9.589461  10.666630        41.0        41.0   \n",
       "4  9.382611  11.297750    9.545383   9.414097        31.0        41.0   \n",
       "\n",
       "   avg_hub_Other  avg_hub_UA  \n",
       "0         16.625        36.0  \n",
       "1         18.000        35.0  \n",
       "2         18.000        33.5  \n",
       "3         17.000        38.5  \n",
       "4         14.000        35.5  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('airlines_long.csv')\n",
    "airline_map = {1: 'AA', 2: 'DL', 3: 'Other', 4: 'UA'}\n",
    "data['airline'] = data['airline_id'].map(airline_map)\n",
    "\n",
    "data_wide = data.pivot(\n",
    "    index=['route_city', 'quarter', 'avg_pop'],\n",
    "    columns='airline',\n",
    "    values=['price', 'logp', 'passengers', 'logq', 'avg_hub']\n",
    ").reset_index()\n",
    "\n",
    "data_wide.columns = [f'{val}_{airline}' if airline else val \n",
    "                     for val, airline in data_wide.columns]\n",
    "data_wide = data_wide.dropna()\n",
    "print(len(data_wide))\n",
    "data_wide.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4847c2",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d7d146",
   "metadata": {},
   "source": [
    "**Why is avg_pop in the demand equation?**  \n",
    "avg_pop captures market size - larger population markets have higher demand. It controls for market size differences across routes. Since population is exogenous to airline pricing decisions, including avg_pop helps identify demand and isolates the price effects captured by the β_jk coefficients.\n",
    "\n",
    "**What do the β_jk coefficients mean under the log-log specification?**  \n",
    "β_jk = % change in Q_j / % change in p_k (cross-price elasticity if j≠k, own-price elasticity if j=k => expect to be negative)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f5d999",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "**Pricing equations (Nash-Bertrand):**\n",
    "\n",
    "For each airline j, FOC from profit maximization:\n",
    "$$p_{jct} = c_{jct} - \\frac{Q_{jct}}{\\frac{\\partial Q_{jct}}{\\partial p_{jct}}}$$\n",
    "\n",
    "Under log-log demand: $\\frac{\\partial Q_{jct}}{\\partial p_{jct}} = \\frac{Q_{jct} \\beta_{jj}}{p_{jct}}$\n",
    "\n",
    "So: $$p_{jct} = c_{jct} - \\frac{p_{jct}}{\\beta_{jj}}$$\n",
    "\n",
    "Rearranging: $$p_{jct} = c_{jct} \\cdot \\frac{\\beta_{jj}}{\\beta_{jj} + 1}$$\n",
    "\n",
    "**8 Valid Instruments for 4 prices:**\n",
    "\n",
    "For each airline $j$'s price $p_{jct}$, two types of instruments:\n",
    "\n",
    "1. **Hausman instruments**: $\\bar{p}_{(-j)ct}$ = average price of other airlines (excluding $j$) in the same route $c$ at time $t$ (4 instruments - one per airline)\n",
    "2. **Same airline's prices in other routes**: $\\bar{p}_{j(-c)t}$ = average price of airline $j$ in all other routes at time $t$ (4 instruments - one per airline)\n",
    "\n",
    "**Validity:** Hausman instruments reflect supply conditions of competitors but are uncorrelated with airline $j$'s demand shock under the covariance assumptions. Prices in other routes share common cost factors across markets but are independent of the current route's demand shock."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b246d57",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "61d0ef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from linearmodels.iv import IV2SLS\n",
    "import statsmodels.api as sm\n",
    "\n",
    "airlines = ['AA', 'DL', 'Other', 'UA']\n",
    "\n",
    "# other airlines' prices in same route\n",
    "data_wide['other_price_AA'] = data_wide[['price_DL', 'price_Other', 'price_UA']].mean(axis=1)\n",
    "data_wide['other_price_DL'] = data_wide[['price_AA', 'price_Other', 'price_UA']].mean(axis=1)\n",
    "data_wide['other_price_UA'] = data_wide[['price_AA', 'price_DL', 'price_Other']].mean(axis=1)\n",
    "data_wide['other_price_Other'] = data_wide[['price_AA', 'price_DL', 'price_UA']].mean(axis=1)\n",
    "\n",
    "# same airline's prices in other routes\n",
    "for airline in airlines:\n",
    "    quarter_means = data_wide.groupby('quarter')[f'price_{airline}'].mean()\n",
    "    quarter_counts = data_wide.groupby('quarter')[f'price_{airline}'].count()\n",
    "    \n",
    "    data_wide[f'other_route_price_{airline}'] = data_wide.apply(\n",
    "        lambda row: (quarter_means[row['quarter']] * quarter_counts[row['quarter']] - row[f'price_{airline}']) / \n",
    "                    (quarter_counts[row['quarter']] - 1),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# all 8 instruments\n",
    "instruments = data_wide[[\n",
    "    'other_price_AA', 'other_route_price_AA',\n",
    "    'other_price_DL', 'other_route_price_DL',\n",
    "    'other_price_Other', 'other_route_price_Other',\n",
    "    'other_price_UA', 'other_route_price_UA'\n",
    "]]\n",
    "\n",
    "results_2sls = {}\n",
    "for airline in airlines:\n",
    "    y = data_wide[f'logq_{airline}']\n",
    "    exog = sm.add_constant(data_wide[['avg_pop']])\n",
    "    endog = data_wide[[f'logp_{a}' for a in airlines]]\n",
    "    \n",
    "    model = IV2SLS(y, exog, endog, instruments).fit()\n",
    "    results_2sls[airline] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a22d675d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AA Demand (2SLS):\n",
      "                          IV-2SLS Estimation Summary                          \n",
      "==============================================================================\n",
      "Dep. Variable:                logq_AA   R-squared:                      0.2409\n",
      "Estimator:                    IV-2SLS   Adj. R-squared:                 0.2173\n",
      "No. Observations:                 167   F-statistic:                    65.886\n",
      "Date:                Mon, Feb 16 2026   P-value (F-stat)                0.0000\n",
      "Time:                        21:18:31   Distribution:                  chi2(5)\n",
      "Cov. Estimator:                robust                                         \n",
      "                                                                              \n",
      "                             Parameter Estimates                              \n",
      "==============================================================================\n",
      "            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "------------------------------------------------------------------------------\n",
      "const          17.815     2.4698     7.2133     0.0000      12.975      22.656\n",
      "avg_pop        0.0006  9.322e-05     6.5507     0.0000      0.0004      0.0008\n",
      "logp_AA       -2.8405     0.5599    -5.0731     0.0000     -3.9379     -1.7431\n",
      "logp_DL        0.6045     0.2263     2.6712     0.0076      0.1610      1.0480\n",
      "logp_Other     0.4386     0.2802     1.5651     0.1176     -0.1107      0.9878\n",
      "logp_UA       -0.2852     0.3028    -0.9419     0.3462     -0.8786      0.3082\n",
      "==============================================================================\n",
      "\n",
      "Endogenous: logp_AA, logp_DL, logp_Other, logp_UA\n",
      "Instruments: other_price_AA, other_route_price_AA, other_price_DL, other_route_price_DL, other_price_Other, other_route_price_Other, other_price_UA, other_route_price_UA\n",
      "Robust Covariance (Heteroskedastic)\n",
      "Debiased: False\n"
     ]
    }
   ],
   "source": [
    "print(f\"AA Demand (2SLS):\")\n",
    "print(results_2sls['AA'].summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5d896816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DL Demand (2SLS):\n",
      "                          IV-2SLS Estimation Summary                          \n",
      "==============================================================================\n",
      "Dep. Variable:                logq_DL   R-squared:                      0.5714\n",
      "Estimator:                    IV-2SLS   Adj. R-squared:                 0.5581\n",
      "No. Observations:                 167   F-statistic:                    275.56\n",
      "Date:                Mon, Feb 16 2026   P-value (F-stat)                0.0000\n",
      "Time:                        21:18:31   Distribution:                  chi2(5)\n",
      "Cov. Estimator:                robust                                         \n",
      "                                                                              \n",
      "                             Parameter Estimates                              \n",
      "==============================================================================\n",
      "            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "------------------------------------------------------------------------------\n",
      "const          17.980     2.1570     8.3358     0.0000      13.753      22.208\n",
      "avg_pop        0.0004  6.943e-05     5.6803     0.0000      0.0003      0.0005\n",
      "logp_AA        0.0958     0.5586     0.1716     0.8638     -0.9990      1.1906\n",
      "logp_DL       -3.0928     0.2466    -12.543     0.0000     -3.5760     -2.6095\n",
      "logp_Other     0.3638     0.2266     1.6054     0.1084     -0.0803      0.8080\n",
      "logp_UA        0.2462     0.2305     1.0680     0.2855     -0.2056      0.6979\n",
      "==============================================================================\n",
      "\n",
      "Endogenous: logp_AA, logp_DL, logp_Other, logp_UA\n",
      "Instruments: other_price_AA, other_route_price_AA, other_price_DL, other_route_price_DL, other_price_Other, other_route_price_Other, other_price_UA, other_route_price_UA\n",
      "Robust Covariance (Heteroskedastic)\n",
      "Debiased: False\n"
     ]
    }
   ],
   "source": [
    "print(f\"DL Demand (2SLS):\")\n",
    "print(results_2sls['DL'].summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1f972a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other Demand (2SLS):\n",
      "                          IV-2SLS Estimation Summary                          \n",
      "==============================================================================\n",
      "Dep. Variable:             logq_Other   R-squared:                      0.3530\n",
      "Estimator:                    IV-2SLS   Adj. R-squared:                 0.3329\n",
      "No. Observations:                 167   F-statistic:                    106.15\n",
      "Date:                Mon, Feb 16 2026   P-value (F-stat)                0.0000\n",
      "Time:                        21:18:31   Distribution:                  chi2(5)\n",
      "Cov. Estimator:                robust                                         \n",
      "                                                                              \n",
      "                             Parameter Estimates                              \n",
      "==============================================================================\n",
      "            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "------------------------------------------------------------------------------\n",
      "const          15.024     2.1448     7.0046     0.0000      10.820      19.227\n",
      "avg_pop        0.0006  7.163e-05     7.7799     0.0000      0.0004      0.0007\n",
      "logp_AA        0.1721     0.3698     0.4653     0.6417     -0.5527      0.8968\n",
      "logp_DL        0.1427     0.3028     0.4713     0.6375     -0.4508      0.7363\n",
      "logp_Other    -1.9037     0.3225    -5.9022     0.0000     -2.5359     -1.2715\n",
      "logp_UA       -0.0304     0.2720    -0.1118     0.9110     -0.5635      0.5027\n",
      "==============================================================================\n",
      "\n",
      "Endogenous: logp_AA, logp_DL, logp_Other, logp_UA\n",
      "Instruments: other_price_AA, other_route_price_AA, other_price_DL, other_route_price_DL, other_price_Other, other_route_price_Other, other_price_UA, other_route_price_UA\n",
      "Robust Covariance (Heteroskedastic)\n",
      "Debiased: False\n"
     ]
    }
   ],
   "source": [
    "print(f\"Other Demand (2SLS):\")\n",
    "print(results_2sls['Other'].summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd93506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate AA+UA merger\n",
    "import numpy as np\n",
    "\n",
    "# Extract coefficients\n",
    "airlines = ['AA', 'DL', 'UA', 'Other']\n",
    "beta = {j: {k: results_2sls[j].params[f'logp_{k}'] for k in airlines} for j in airlines}\n",
    "alpha = {j: results_2sls[j].params['const'] for j in airlines}\n",
    "beta_pop = {j: results_2sls[j].params['avg_pop'] for j in airlines}\n",
    "\n",
    "# Get residuals (linearmodels uses .residuals, not .resid)\n",
    "data_cf = data_wide.copy()\n",
    "data_orig = data_wide.copy()\n",
    "for j in ['AA', 'DL', 'UA', 'Other']:\n",
    "    data_cf[f'resid_{j}'] = results_2sls[j].residuals\n",
    "\n",
    "# Iterate to equilibrium\n",
    "tol, max_iter = 0.01, 500\n",
    "for it in range(max_iter):\n",
    "    # Update log prices\n",
    "    for a in ['AA', 'DL', 'UA', 'Other']:\n",
    "        data_cf[f'logp_{a}'] = np.log(np.maximum(data_cf[f'price_{a}'], 0.01))\n",
    "    \n",
    "    # Predict quantities\n",
    "    for j in ['AA', 'DL', 'UA']:\n",
    "        data_cf[f'logq_{j}'] = (alpha[j] + beta_pop[j] * data_cf['avg_pop'] + \n",
    "                                sum(beta[j][k] * data_cf[f'logp_{k}'] for k in airlines) + \n",
    "                                data_cf[f'resid_{j}'])\n",
    "    \n",
    "    qty = {j: np.exp(data_cf[f'logq_{j}']) for j in ['AA', 'DL', 'UA']}\n",
    "    ratio_UA_AA = qty['UA'] / qty['AA']\n",
    "    ratio_AA_UA = qty['AA'] / qty['UA']\n",
    "    \n",
    "    # FOCs: merged AA+UA, separate DL, Other fixed\n",
    "    p_new = {}\n",
    "    p_new['AA'] = (data_cf['mc_AA'] - data_cf['price_AA']/beta['AA']['AA'] - \n",
    "                   (data_cf['price_UA'] - data_cf['mc_UA']) * ratio_UA_AA * beta['UA']['AA']/beta['AA']['AA'])\n",
    "    p_new['UA'] = (data_cf['mc_UA'] - data_cf['price_UA']/beta['UA']['UA'] - \n",
    "                   (data_cf['price_AA'] - data_cf['mc_AA']) * ratio_AA_UA * beta['AA']['UA']/beta['UA']['UA'])\n",
    "    p_new['DL'] = data_cf['mc_DL'] - data_cf['price_DL']/beta['DL']['DL']\n",
    "    \n",
    "    # Check convergence\n",
    "    diff = max([abs(p_new[j] - data_cf[f'price_{j}']).max() for j in ['AA', 'DL', 'UA']])\n",
    "    if diff < tol:\n",
    "        print(f\"Converged after {it+1} iterations (diff={diff:.6f})\")\n",
    "        break\n",
    "    \n",
    "    # Update prices with damping\n",
    "    for j in ['AA', 'DL', 'UA']:\n",
    "        data_cf[f'price_{j}'] = 0.1 * p_new[j] + 0.9 * data_cf[f'price_{j}']\n",
    "\n",
    "# Final quantities\n",
    "for a in ['AA', 'DL', 'UA', 'Other']:\n",
    "    data_cf[f'logp_{a}'] = np.log(np.maximum(data_cf[f'price_{a}'], 0.01))\n",
    "for j in ['AA', 'DL', 'UA']:\n",
    "    data_cf[f'logq_{j}'] = (alpha[j] + beta_pop[j] * data_cf['avg_pop'] + \n",
    "                            sum(beta[j][k] * data_cf[f'logp_{k}'] for k in airlines) + \n",
    "                            data_cf[f'resid_{j}'])\n",
    "\n",
    "# Price changes\n",
    "print(\"\\nAverage Price Changes (%):\")\n",
    "for a in ['AA', 'DL', 'UA', 'Other']:\n",
    "    pct_change = ((data_cf[f'price_{a}'] - data_orig[f'price_{a}']) / data_orig[f'price_{a}'] * 100).mean()\n",
    "    print(f\"  {a}: {pct_change:.2f}%\")\n",
    "\n",
    "# Profit changes\n",
    "profit_pre = {j: (data_orig[f'price_{j}'] - data_orig[f'mc_{j}']) * np.exp(data_orig[f'logq_{j}']) \n",
    "              for j in ['AA', 'DL', 'UA']}\n",
    "profit_post = {j: (data_cf[f'price_{j}'] - data_cf[f'mc_{j}']) * np.exp(data_cf[f'logq_{j}']) \n",
    "               for j in ['AA', 'DL', 'UA']}\n",
    "\n",
    "print(\"\\nAverage Profit Changes ($):\")\n",
    "print(f\"  AA+UA: ${(profit_post['AA'] + profit_post['UA'] - profit_pre['AA'] - profit_pre['UA']).mean():,.2f}\")\n",
    "print(f\"  DL: ${(profit_post['DL'] - profit_pre['DL']).mean():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d068c20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UA Demand (2SLS):\n",
      "                          IV-2SLS Estimation Summary                          \n",
      "==============================================================================\n",
      "Dep. Variable:                logq_UA   R-squared:                      0.1010\n",
      "Estimator:                    IV-2SLS   Adj. R-squared:                 0.0731\n",
      "No. Observations:                 167   F-statistic:                    103.95\n",
      "Date:                Mon, Feb 16 2026   P-value (F-stat)                0.0000\n",
      "Time:                        21:18:31   Distribution:                  chi2(5)\n",
      "Cov. Estimator:                robust                                         \n",
      "                                                                              \n",
      "                             Parameter Estimates                              \n",
      "==============================================================================\n",
      "            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "------------------------------------------------------------------------------\n",
      "const          25.036     3.0251     8.2763     0.0000      19.107      30.965\n",
      "avg_pop        0.0003     0.0001     2.4930     0.0127   7.258e-05      0.0006\n",
      "logp_AA       -0.7037     0.7723    -0.9112     0.3622     -2.2174      0.8099\n",
      "logp_DL       -0.1084     0.3498    -0.3100     0.7566     -0.7941      0.5772\n",
      "logp_Other    -0.9085     0.3641    -2.4954     0.0126     -1.6222     -0.1949\n",
      "logp_UA       -1.9261     0.6300    -3.0571     0.0022     -3.1610     -0.6912\n",
      "==============================================================================\n",
      "\n",
      "Endogenous: logp_AA, logp_DL, logp_Other, logp_UA\n",
      "Instruments: other_price_AA, other_route_price_AA, other_price_DL, other_route_price_DL, other_price_Other, other_route_price_Other, other_price_UA, other_route_price_UA\n",
      "Robust Covariance (Heteroskedastic)\n",
      "Debiased: False\n"
     ]
    }
   ],
   "source": [
    "print(f\"UA Demand (2SLS):\")\n",
    "print(results_2sls['UA'].summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50829c1c",
   "metadata": {},
   "source": [
    "**Estimated Coefficients (2SLS):**\n",
    "\n",
    "See regression summaries above for actual coefficients.\n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "- **Own-price elasticities** (β_jj): Negative coefficients indicate demand decreases with own price.\n",
    "- **Cross-price elasticities** (β_jk, j≠k): Positive coefficients indicate substitutes. Negative coefficients indicate complements.\n",
    "- **Population effect** (β^POP): Positive and significant - larger markets have higher demand for all airlines.\n",
    "- **Intercepts** (α_j): Capture airline-specific baseline demand levels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bbc81c",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9a157e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Implied Marginal Costs Summary:\n",
      "\n",
      "AA:\n",
      "  Mean MC: $104.54141\n",
      "  Std Dev MC: $50.63613\n",
      "  Min MC: $29.80579\n",
      "  Max MC: $429.59210\n",
      "\n",
      "DL:\n",
      "  Mean MC: $127.00208\n",
      "  Std Dev MC: $86.91077\n",
      "  Min MC: $21.65324\n",
      "  Max MC: $494.64116\n",
      "\n",
      "UA:\n",
      "  Mean MC: $75.65881\n",
      "  Std Dev MC: $46.71486\n",
      "  Min MC: $1.44246\n",
      "  Max MC: $232.71750\n"
     ]
    }
   ],
   "source": [
    "# Compute marginal costs: MC = P + P / β_jj\n",
    "airlines_mc = ['AA', 'DL', 'UA']\n",
    "\n",
    "for airline in airlines_mc:\n",
    "    beta_jj = results_2sls[airline].params[f'logp_{airline}']\n",
    "    data_wide[f'mc_{airline}'] = data_wide[f'price_{airline}'] + data_wide[f'price_{airline}'] / beta_jj\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"Implied Marginal Costs Summary:\")\n",
    "for airline in airlines_mc:\n",
    "    mc_col = f'mc_{airline}'\n",
    "    valid_mc = data_wide[mc_col].dropna()\n",
    "\n",
    "    print(f\"\\n{airline}:\")\n",
    "    print(f\"  Mean MC: ${valid_mc.mean():.5f}\")\n",
    "    print(f\"  Std Dev MC: ${valid_mc.std():.5f}\")\n",
    "    print(f\"  Min MC: ${valid_mc.min():.5f}\")\n",
    "    print(f\"  Max MC: ${valid_mc.max():.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c047ab5",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b8048e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converged after 122 iterations\n"
     ]
    }
   ],
   "source": [
    "# simulate AA+UA merger\n",
    "import numpy as np\n",
    "\n",
    "beta = lambda j, k: results_2sls[j].params[f'logp_{k}']\n",
    "\n",
    "data_orig = data_wide.copy()\n",
    "for a in ['AA', 'UA', 'DL']:\n",
    "    data_orig[f'resid_{a}'] = results_2sls[a].resids.values\n",
    "data_cf = data_orig.copy()\n",
    "\n",
    "# find equilibrium\n",
    "for it in range(500):\n",
    "    for a in ['AA', 'UA', 'DL', 'Other']:\n",
    "        data_cf[f'logp_{a}'] = np.log(np.maximum(data_cf[f'price_{a}'], 0.01))\n",
    "    \n",
    "    for a in ['AA', 'UA', 'DL']:\n",
    "        data_cf[f'logq_{a}'] = (results_2sls[a].params['const'] + \n",
    "            results_2sls[a].params['avg_pop'] * data_cf['avg_pop'] +\n",
    "            sum(beta(a, k) * data_cf[f'logp_{k}'] for k in ['AA', 'DL', 'Other', 'UA']) +\n",
    "            data_cf[f'resid_{a}'])\n",
    "    \n",
    "    q_AA, q_UA = np.exp(data_cf['logq_AA']), np.exp(data_cf['logq_UA'])\n",
    "    r_UA_AA, r_AA_UA = q_UA / q_AA, q_AA / q_UA\n",
    "    \n",
    "    # FOCs: merged firm (AA+UA) internalizes cross-effects, DL Nash-Bertrand\n",
    "    p_new_AA = (data_cf['mc_AA'] - data_cf['price_AA']/beta('AA', 'AA') - \n",
    "                (data_cf['price_UA'] - data_cf['mc_UA']) * r_UA_AA * beta('UA', 'AA')/beta('AA', 'AA'))\n",
    "    p_new_UA = (data_cf['mc_UA'] - data_cf['price_UA']/beta('UA', 'UA') - \n",
    "                (data_cf['price_AA'] - data_cf['mc_AA']) * r_AA_UA * beta('AA', 'UA')/beta('UA', 'UA'))\n",
    "    p_new_DL = data_cf['mc_DL'] - data_cf['price_DL']/beta('DL', 'DL')\n",
    "    \n",
    "    # check for convergence\n",
    "    diff = max(np.abs(p_new_AA - data_cf['price_AA']).max(),\n",
    "               np.abs(p_new_UA - data_cf['price_UA']).max(),\n",
    "               np.abs(p_new_DL - data_cf['price_DL']).max())\n",
    "    if diff < 0.01:\n",
    "        print(f\"converged after {it+1} iterations\")\n",
    "        break\n",
    "    \n",
    "    # update prices with damping\n",
    "    data_cf['price_AA'] = 0.1*p_new_AA + 0.9*data_cf['price_AA']\n",
    "    data_cf['price_UA'] = 0.1*p_new_UA + 0.9*data_cf['price_UA']\n",
    "    data_cf['price_DL'] = 0.1*p_new_DL + 0.9*data_cf['price_DL']\n",
    "\n",
    "# quantities\n",
    "for a in ['AA', 'UA', 'DL']:\n",
    "    data_cf[f'logp_{a}'] = np.log(np.maximum(data_cf[f'price_{a}'], 0.01))\n",
    "    data_cf[f'logq_{a}'] = (results_2sls[a].params['const'] + \n",
    "        results_2sls[a].params['avg_pop'] * data_cf['avg_pop'] +\n",
    "        sum(beta(a, k) * data_cf[f'logp_{k}'] for k in ['AA', 'DL', 'Other', 'UA']) +\n",
    "        data_cf[f'resid_{a}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4b13a0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Price Changes (%):\n",
      "  AA: -13.24%\n",
      "  UA: -21.99%\n",
      "  DL: 0.00%\n",
      "  Other: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# price changes\n",
    "price_changes = {}\n",
    "for a in ['AA', 'UA', 'DL', 'Other']:\n",
    "    if a == 'Other':\n",
    "        price_changes[a] = 0.0\n",
    "    else:\n",
    "        price_changes[a] = ((data_cf[f'price_{a}'] - data_orig[f'price_{a}']) / data_orig[f'price_{a}'] * 100).mean()\n",
    "\n",
    "print(\"Average Price Changes (%):\")\n",
    "for a in ['AA', 'UA', 'DL', 'Other']:\n",
    "    print(f\"  {a}: {price_changes[a]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "98e1996e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Profit Changes ($):\n",
      "  AA: $113,277.69\n",
      "  UA: $127,521.50\n",
      "  DL: $-23,511.78\n",
      "\n",
      "  AA+UA (combined): $240,799.20\n"
     ]
    }
   ],
   "source": [
    "# Profit changes\n",
    "profit_pre = {}\n",
    "profit_post = {}\n",
    "for a in ['AA', 'UA', 'DL']:\n",
    "    profit_pre[a] = (data_orig[f'price_{a}'] - data_orig[f'mc_{a}']) * np.exp(data_orig[f'logq_{a}'])\n",
    "    profit_post[a] = (data_cf[f'price_{a}'] - data_cf[f'mc_{a}']) * np.exp(data_cf[f'logq_{a}'])\n",
    "\n",
    "print(\"Average Profit Changes ($):\")\n",
    "for a in ['AA', 'UA', 'DL']:\n",
    "    print(f\"  {a}: ${(profit_post[a] - profit_pre[a]).mean():,.2f}\")\n",
    "print(f\"\\n  AA+UA (combined): ${(profit_post['AA'] + profit_post['UA'] - profit_pre['AA'] - profit_pre['UA']).mean():,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd7b488",
   "metadata": {},
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2c2d5e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating AA+DL merger...\n",
      "Simulating UA+DL merger...\n"
     ]
    }
   ],
   "source": [
    "# simulate AA+DL and UA+DL mergers\n",
    "def simulate_merger(merged_airlines, data_orig):\n",
    "    data_cf = data_orig.copy()\n",
    "    beta = lambda j, k: results_2sls[j].params[f'logp_{k}']\n",
    "    \n",
    "    for it in range(500):\n",
    "        # update log prices\n",
    "        for a in ['AA', 'UA', 'DL', 'Other']:\n",
    "            data_cf[f'logp_{a}'] = np.log(np.maximum(data_cf[f'price_{a}'], 0.01))\n",
    "        \n",
    "        # predict quantities\n",
    "        for a in ['AA', 'UA', 'DL']:\n",
    "            data_cf[f'logq_{a}'] = (results_2sls[a].params['const'] + \n",
    "                results_2sls[a].params['avg_pop'] * data_cf['avg_pop'] +\n",
    "                sum(beta(a, k) * data_cf[f'logp_{k}'] for k in ['AA', 'DL', 'Other', 'UA']) +\n",
    "                data_cf[f'resid_{a}'])\n",
    "        \n",
    "        # get quantities and ratios for merged firms\n",
    "        q = {a: np.exp(data_cf[f'logq_{a}']) for a in merged_airlines}\n",
    "        \n",
    "        # FOCs: merged firms internalize cross-effects, others Nash-Bertrand\n",
    "        p_new = {}\n",
    "        if set(merged_airlines) == {'AA', 'DL'}:\n",
    "            r_DL_AA, r_AA_DL = q['DL'] / q['AA'], q['AA'] / q['DL']\n",
    "            p_new['AA'] = (data_cf['mc_AA'] - data_cf['price_AA']/beta('AA', 'AA') - \n",
    "                          (data_cf['price_DL'] - data_cf['mc_DL']) * r_DL_AA * beta('DL', 'AA')/beta('AA', 'AA'))\n",
    "            p_new['DL'] = (data_cf['mc_DL'] - data_cf['price_DL']/beta('DL', 'DL') - \n",
    "                          (data_cf['price_AA'] - data_cf['mc_AA']) * r_AA_DL * beta('AA', 'DL')/beta('DL', 'DL'))\n",
    "            p_new['UA'] = data_cf['mc_UA'] - data_cf['price_UA']/beta('UA', 'UA')\n",
    "        elif set(merged_airlines) == {'UA', 'DL'}:\n",
    "            r_DL_UA, r_UA_DL = q['DL'] / q['UA'], q['UA'] / q['DL']\n",
    "            p_new['UA'] = (data_cf['mc_UA'] - data_cf['price_UA']/beta('UA', 'UA') - \n",
    "                          (data_cf['price_DL'] - data_cf['mc_DL']) * r_DL_UA * beta('DL', 'UA')/beta('UA', 'UA'))\n",
    "            p_new['DL'] = (data_cf['mc_DL'] - data_cf['price_DL']/beta('DL', 'DL') - \n",
    "                          (data_cf['price_UA'] - data_cf['mc_UA']) * r_UA_DL * beta('UA', 'DL')/beta('DL', 'DL'))\n",
    "            p_new['AA'] = data_cf['mc_AA'] - data_cf['price_AA']/beta('AA', 'AA')\n",
    "        else:  # AA+UA\n",
    "            r_UA_AA, r_AA_UA = q['UA'] / q['AA'], q['AA'] / q['UA']\n",
    "            p_new['AA'] = (data_cf['mc_AA'] - data_cf['price_AA']/beta('AA', 'AA') - \n",
    "                          (data_cf['price_UA'] - data_cf['mc_UA']) * r_UA_AA * beta('UA', 'AA')/beta('AA', 'AA'))\n",
    "            p_new['UA'] = (data_cf['mc_UA'] - data_cf['price_UA']/beta('UA', 'UA') - \n",
    "                          (data_cf['price_AA'] - data_cf['mc_AA']) * r_AA_UA * beta('AA', 'UA')/beta('UA', 'UA'))\n",
    "            p_new['DL'] = data_cf['mc_DL'] - data_cf['price_DL']/beta('DL', 'DL')\n",
    "        \n",
    "        # check convergence\n",
    "        diff = max([np.abs(p_new[a] - data_cf[f'price_{a}']).max() for a in p_new.keys()])\n",
    "        if diff < 0.01:\n",
    "            break\n",
    "        \n",
    "        # Update prices\n",
    "        for a in p_new.keys():\n",
    "            data_cf[f'price_{a}'] = 0.1*p_new[a] + 0.9*data_cf[f'price_{a}']\n",
    "    \n",
    "    # Final quantities\n",
    "    for a in ['AA', 'UA', 'DL', 'Other']:\n",
    "        data_cf[f'logp_{a}'] = np.log(np.maximum(data_cf[f'price_{a}'], 0.01))\n",
    "    for a in ['AA', 'UA', 'DL']:\n",
    "        data_cf[f'logq_{a}'] = (results_2sls[a].params['const'] + \n",
    "            results_2sls[a].params['avg_pop'] * data_cf['avg_pop'] +\n",
    "            sum(beta(a, k) * data_cf[f'logp_{k}'] for k in ['AA', 'DL', 'Other', 'UA']) +\n",
    "            data_cf[f'resid_{a}'])\n",
    "    \n",
    "    return data_cf\n",
    "\n",
    "# from previous question\n",
    "results_mergers = {'AA+UA': data_cf}\n",
    "\n",
    "for merger in [['AA', 'DL'], ['UA', 'DL']]:\n",
    "    merger_name = '+'.join(merger)\n",
    "    print(f\"Simulating {merger_name} merger...\")\n",
    "    results_mergers[merger_name] = simulate_merger(merger, data_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724b59cd",
   "metadata": {},
   "source": [
    "### Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f9bf97ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price Changes (%) by Merger:\n",
      "\n",
      "  Airline  AA+UA  AA+DL  UA+DL\n",
      "0      AA -13.24   6.61   0.00\n",
      "1      UA -21.99   0.00   8.06\n",
      "2      DL   0.00   6.58 -20.63\n",
      "3   Other   0.00   0.00   0.00\n"
     ]
    }
   ],
   "source": [
    "# compare price changes across all 3 mergers\n",
    "print(\"Price Changes (%) by Merger:\\n\")\n",
    "price_comparison = pd.DataFrame({\n",
    "    'Airline': ['AA', 'UA', 'DL', 'Other']\n",
    "})\n",
    "\n",
    "for merger_name in ['AA+UA', 'AA+DL', 'UA+DL']:\n",
    "    data_cf_merger = results_mergers[merger_name]\n",
    "    price_changes = []\n",
    "    for a in ['AA', 'UA', 'DL', 'Other']:\n",
    "        if a == 'Other':\n",
    "            price_changes.append(0.0)\n",
    "        else:\n",
    "            pct = ((data_cf_merger[f'price_{a}'] - data_orig[f'price_{a}']) / data_orig[f'price_{a}'] * 100).mean()\n",
    "            price_changes.append(pct)\n",
    "    price_comparison[merger_name] = price_changes\n",
    "\n",
    "print(price_comparison.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8a2d4661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit Changes by Merger:\n",
      "\n",
      "    Airline      AA+UA     AA+DL      UA+DL\n",
      "0        AA  113277.69   2881.77 -420449.65\n",
      "1        UA  127521.50 -44246.22   73643.26\n",
      "2        DL  -23511.78   6007.54  -13545.20\n",
      "3  Combined  240799.20   8889.31   60098.05\n"
     ]
    }
   ],
   "source": [
    "# compare profit changes across all 3 mergers\n",
    "print(\"profit Changes by Merger:\\n\")\n",
    "profit_comparison = pd.DataFrame({\n",
    "    'Airline': ['AA', 'UA', 'DL', 'Combined']\n",
    "})\n",
    "\n",
    "for merger_name in ['AA+UA', 'AA+DL', 'UA+DL']:\n",
    "    data_cf_merger = results_mergers[merger_name]\n",
    "    profit_changes = []\n",
    "    \n",
    "    # individual airline profits\n",
    "    for a in ['AA', 'UA', 'DL']:\n",
    "        profit_pre = (data_orig[f'price_{a}'] - data_orig[f'mc_{a}']) * np.exp(data_orig[f'logq_{a}'])\n",
    "        profit_post = (data_cf_merger[f'price_{a}'] - data_cf_merger[f'mc_{a}']) * np.exp(data_cf_merger[f'logq_{a}'])\n",
    "        profit_changes.append((profit_post - profit_pre).mean())\n",
    "    \n",
    "    # combined merged firm profit\n",
    "    merged = merger_name.split('+')\n",
    "    profit_pre_combined = sum([(data_orig[f'price_{a}'] - data_orig[f'mc_{a}']) * np.exp(data_orig[f'logq_{a}']) for a in merged])\n",
    "    profit_post_combined = sum([(data_cf_merger[f'price_{a}'] - data_cf_merger[f'mc_{a}']) * np.exp(data_cf_merger[f'logq_{a}']) for a in merged])\n",
    "    profit_changes.append((profit_post_combined - profit_pre_combined).mean())\n",
    "    \n",
    "    profit_comparison[merger_name] = profit_changes\n",
    "\n",
    "print(profit_comparison.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87243f6",
   "metadata": {},
   "source": [
    "\n",
    "**Price Effects:**\n",
    "\n",
    "1. **AA+UA merger**: Both merged airlines reduce prices (AA: -13.24%, UA: -21.99%), while DL's price remains unchanged. This suggests AA and UA are close substitutes, and internalizing cross-price effects leads to lower prices.\n",
    "\n",
    "2. **AA+DL merger**: The merged firm (AA+DL) internalizes cross-effects, while UA adjusts competitively.\n",
    "\n",
    "3. **UA+DL merger**: Similar pattern with UA+DL merged and AA as the competitor.\n",
    "\n",
    "**Profit Effects:**\n",
    "\n",
    "1. **AA+UA merger**: The merged firm gains $240,799 in combined profits, while DL loses $23,512. The price reductions increase market share and total demand, offsetting lower margins.\n",
    "\n",
    "2. **AA+DL merger**: The small combined profit gain suggests AA and DL are less substitutable than AA and UA, so internalizing cross-effects provides less strategic advantage.\n",
    "\n",
    "3. **UA+DL merger**: AA is highly vulnerable when its two main competitors merge. This suggests AA competes closely with both UA and DL.\n",
    "\n",
    "Overall, despite price reductions, merged firms can increase profits by capturing market share from competitors and internalizing competitive externalities. We also see, that the non-merged competitor adjusts prices according to Nash-Bertrand, but may still lose profits due to the merged firm's strategic advantage. The magnitude of price and profit changes depends on the cross-price elasticities between merging firms. Higher substitutability leads to larger strategic effects."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
